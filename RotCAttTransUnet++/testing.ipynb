{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage.transform import resize\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_for_training/Synapse/RawData/Training\\img ../data_for_training/Synapse/RawData/Training\\label\n"
     ]
    }
   ],
   "source": [
    "root = \"../data_for_training/Synapse/RawData/Training\"\n",
    "\n",
    "root_images = os.path.join(root, \"img\")\n",
    "root_labels = os.path.join(root, \"label\")\n",
    "\n",
    "print(root_images, root_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(folder_path, formatted_extension): \n",
    "    paths = sorted(glob(os.path.join(folder_path, formatted_extension)))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "images = get_all_files(root_images, \"*.nii.gz\")\n",
    "labels = get_all_files(root_labels, \"*.nii.gz\")\n",
    "\n",
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_for_training/Synapse/RawData/Training\\img\\img0001.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0001.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0002.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0002.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0003.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0003.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0004.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0004.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0005.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0005.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0006.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0006.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0007.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0007.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0008.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0008.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0009.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0009.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0010.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0010.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0021.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0021.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0022.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0022.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0023.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0023.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0024.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0024.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0025.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0025.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0026.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0026.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0027.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0027.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0028.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0028.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0029.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0029.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0030.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0030.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0031.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0031.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0032.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0032.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0033.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0033.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0034.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0034.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0035.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0035.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0036.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0036.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0037.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0037.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0038.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0038.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0039.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0039.nii.gz\n",
      "../data_for_training/Synapse/RawData/Training\\img\\img0040.nii.gz ../data_for_training/Synapse/RawData/Training\\label\\label0040.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip (images, labels): \n",
    "    print(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_from_volumetric_data(image_volume, mask_volume, start_idx, num_slice=8):\n",
    "    end_idx = start_idx + num_slice\n",
    "\n",
    "    images = torch.empty(num_slice, 1, 256, 256)\n",
    "    masks = torch.empty(num_slice, 1, 256, 256)\n",
    "\n",
    "    for i in range(start_idx, end_idx, 1):\n",
    "        image = image_volume[:, :, i]\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        images[i - start_idx, :, :, :] = image\n",
    "\n",
    "        mask = mask_volume[:, :, i]\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        mask = F.one_hot(mask, num_classes=14)\n",
    "        mask = mask.numpy()\n",
    "        mask = resize(mask, (256, 256, 14),\n",
    "                      preserve_range=True, anti_aliasing=True)\n",
    "        mask = torch.from_numpy(mask) \n",
    "        mask = torch.argmax(mask, dim=-1)\n",
    "        mask = torch.unsqueeze(mask, dim=0) \n",
    "\n",
    "        masks[i - start_idx, :, :, :] = mask\n",
    "\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1, 256, 256]) torch.Size([9, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "image_volume = nib.load(\n",
    "    \"../data_for_training/Synapse/RawData/Training\\img\\img0001.nii.gz\").get_fdata()\n",
    "\n",
    "mask_volume = nib.load(\n",
    "    \"../data_for_training/Synapse/RawData/Training\\label\\label0001.nii.gz\").get_fdata()\n",
    "\n",
    "images, masks = get_slice_from_volumetric_data(image_volume, mask_volume, 0, num_slice=9)\n",
    "\n",
    "print(images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(mask_volume))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
