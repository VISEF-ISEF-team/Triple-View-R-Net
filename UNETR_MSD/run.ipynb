{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from unetr_2d import build_unetr_2d\n",
    "from metrics import dice_loss, dice_coef\n",
    "from patchify import patchify\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNETR  Configration\n",
    "cf = {}\n",
    "cf[\"image_size\"] = 256\n",
    "cf[\"num_classes\"] = 2\n",
    "cf[\"num_channels\"] = 3\n",
    "cf[\"num_layers\"] = 12\n",
    "cf[\"hidden_dim\"] = 128\n",
    "cf[\"mlp_dim\"] = 32\n",
    "cf[\"num_heads\"] = 6\n",
    "cf[\"dropout_rate\"] = 0.1\n",
    "cf[\"patch_size\"] = 16\n",
    "cf[\"num_patches\"] = (cf[\"image_size\"]**2) // (cf[\"patch_size\"]**2)\n",
    "cf[\"flat_patches_shape\"] = (\n",
    "    cf[\"num_patches\"],\n",
    "    cf[\"patch_size\"] * cf[\"patch_size\"] * cf[\"num_channels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path, split=0.1):\n",
    "    # Loading the images and masks\n",
    "    X = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
    "    Y = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
    "\n",
    "    # Spliting the data into training and testing\n",
    "    split_size = int(len(X) * split)\n",
    "\n",
    "    train_x, valid_x = train_test_split(X, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(Y, test_size=split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Processing to patches\n",
    "    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, cf[\"patch_size\"])\n",
    "    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    mask = mask / 255.0\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape(cf[\"flat_patches_shape\"])\n",
    "    y.set_shape([cf[\"image_size\"], cf[\"image_size\"], 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \t2452 - 2452\n",
      "Valid: \t306 - 306\n",
      "Test: \t306 - 306\n"
     ]
    }
   ],
   "source": [
    "# Directory for storing files\n",
    "create_dir(\"files\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "lr = 0.1\n",
    "num_epochs = 1\n",
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "csv_path = os.path.join(\"files\", \"log.csv\")\n",
    "\n",
    "# Dataset\n",
    "dataset_path = \"../data/MSD\"\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n",
    "print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-15\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNETR_2D\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 768)]   0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256, 128)     98432       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 256, 128)    0           ['dense[0][0]']                  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 256, 128)    256         ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 256, 128)    395648      ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256, 128)     0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 256, 128)    256         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256, 32)      4128        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256, 32)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256, 128)     4224        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256, 128)     0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 256, 128)     0           ['dropout_1[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 256, 128)    256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 256, 128)    395648      ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 256, 128)     0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 256, 128)    256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256, 32)      4128        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256, 32)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256, 128)     4224        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256, 128)     0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 256, 128)     0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 256, 128)    256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 256, 128)    395648      ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 256, 128)     0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 256, 128)    256         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256, 32)      4128        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 256, 32)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256, 128)     4224        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 256, 128)     0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 256, 128)     0           ['dropout_5[0][0]',              \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 256, 128)    256         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 256, 128)    395648      ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 256, 128)     0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 256, 128)    256         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 256, 32)      4128        ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256, 32)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 256, 128)     4224        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 256, 128)     0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 256, 128)     0           ['dropout_7[0][0]',              \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 256, 128)    256         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 256, 128)    395648      ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 256, 128)     0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 256, 128)    256         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256, 32)      4128        ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 256, 32)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256, 128)     4224        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 256, 128)     0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 256, 128)     0           ['dropout_9[0][0]',              \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 256, 128)    256         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 256, 128)    395648      ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 256, 128)     0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 256, 128)    256         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 256, 32)      4128        ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 256, 32)      0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 256, 128)     4224        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 256, 128)     0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 256, 128)     0           ['dropout_11[0][0]',             \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 256, 128)    256         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 256, 128)    395648      ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 256, 128)     0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 256, 128)    256         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 256, 32)      4128        ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 256, 32)      0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 256, 128)     4224        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 256, 128)     0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 256, 128)     0           ['dropout_13[0][0]',             \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 256, 128)    256         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 256, 128)    395648      ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 256, 128)     0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 256, 128)    256         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 256, 32)      4128        ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 256, 32)      0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 256, 128)     4224        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 256, 128)     0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 256, 128)     0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 256, 128)    256         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 256, 128)    395648      ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 256, 128)     0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 256, 128)    256         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 256, 32)      4128        ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 256, 32)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 256, 128)     4224        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 256, 128)     0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 256, 128)     0           ['dropout_17[0][0]',             \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 256, 128)    256         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 256, 128)    395648      ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 256, 128)     0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 256, 128)    256         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 256, 32)      4128        ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 256, 32)      0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 256, 128)     4224        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 256, 128)     0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 256, 128)     0           ['dropout_19[0][0]',             \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 256, 128)    256         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 256, 128)    395648      ['layer_normalization_20[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 256, 128)     0           ['multi_head_attention_10[0][0]',\n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 256, 128)    256         ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 256, 32)      4128        ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 256, 32)      0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 256, 128)     4224        ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 256, 128)     0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 256, 128)     0           ['dropout_21[0][0]',             \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 256, 128)    256         ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 256, 128)    395648      ['layer_normalization_22[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 256, 128)     0           ['multi_head_attention_11[0][0]',\n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 256, 128)    256         ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 256, 32)      4128        ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 256, 32)      0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 256, 128)     4224        ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 16, 16, 128)  0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 256, 128)     0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 128)  65664      ['reshape_3[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 256, 128)     0           ['dropout_23[0][0]',             \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 128)  147584      ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 16, 16, 128)  0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 128)  512        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 128)  65664      ['reshape_4[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 32, 32, 128)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 16, 16, 128)  0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  're_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 64)  32832       ['reshape_2[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 64)   36928       ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 16, 16, 128)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 128)  147584      ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 64)  16448       ['re_lu_3[0][0]']                \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 32, 32, 32)  16416       ['reshape_1[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 64)   36928       ['conv2d_transpose_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 32)   9248        ['conv2d_transpose_6[0][0]']     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 64)  32832       ['re_lu_2[0][0]']                \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 32, 32, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  're_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 64, 64, 32)  4128        ['re_lu_7[0][0]']                \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 32)   9248        ['conv2d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 64, 64, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 64)   36928       ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 128, 128, 32  4128       ['re_lu_8[0][0]']                \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 128, 128, 32  9248        ['conv2d_transpose_8[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 128, 128, 32  128        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 128, 128, 32  8224       ['re_lu_6[0][0]']                \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 128, 128, 32  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                )                                 're_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 256, 256, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 32  128        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 16  448         ['reshape[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 16  64         ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 32  9248        ['re_lu_10[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 128, 128, 32  128        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 256, 256, 16  2320        ['re_lu_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 16  64         ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 256, 256, 16  2064       ['re_lu_11[0][0]']               \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                )                                 're_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 256, 256, 16  64         ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_14[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 256, 256, 16  2320        ['re_lu_14[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 256, 256, 16  64         ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 256, 256, 16  0           ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 1)  17          ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,044,401\n",
      "Trainable params: 6,042,673\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = build_unetr_2d(cf)\n",
    "model.compile(\n",
    "    loss=dice_loss, \n",
    "    optimizer=SGD(lr), \n",
    "    metrics=[dice_coef, \"acc\"]\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - ETA: 0s - loss: 0.9590 - dice_coef: 0.0410 - acc: 0.5165\n",
      "Epoch 1: val_loss improved from inf to 0.95544, saving model to files\\model.h5\n",
      "307/307 [==============================] - 119s 326ms/step - loss: 0.9590 - dice_coef: 0.0410 - acc: 0.5165 - val_loss: 0.9554 - val_dice_coef: 0.0458 - val_acc: 0.5475 - lr: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2885488dfd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    CSVLogger(csv_path),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for storing results\n",
    "create_dir(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model \n",
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "model = tf.keras.models.load_model(\n",
    "    model_path, \n",
    "    custom_objects={\n",
    "        'dice_loss': dice_loss,\n",
    "        'dice_coef': dice_coef\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "Iteration: 1\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "Iteration: 2\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "Iteration: 3\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "Iteration: 4\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "Iteration: 5\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "Iteration: 6\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:01<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "Iteration: 7\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "Iteration: 8\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "Iteration: 9\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "Iteration: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (x, y) in enumerate(tqdm(zip(test_x, test_y), total=10)):\n",
    "    \n",
    "    print(f\"Iteration: {index}\")\n",
    "    \n",
    "    # Stopping condition\n",
    "    if (index==10): break\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    x = image / 255.0\n",
    "    print(x.shape)\n",
    "\n",
    "    patch_shape = (cf[\"patch_size\"], cf[\"patch_size\"], cf[\"num_channels\"])\n",
    "    patches = patchify(x, patch_shape, cf[\"patch_size\"])\n",
    "    patches = np.reshape(patches, cf[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "    patches = np.expand_dims(patches, axis=0)\n",
    "    \n",
    "    # Read Mask\n",
    "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (cf[\"image_size\"], cf[\"image_size\"]))\n",
    "    mask = mask / 255.0\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "    print(mask.shape)\n",
    "\n",
    "    # Prediction\n",
    "    pred = model.predict(patches, verbose=0)[0]\n",
    "    pred = np.concatenate([pred, pred, pred], axis=-1)\n",
    "    print(pred.shape)\n",
    "\n",
    "    # Save final mask\n",
    "    cat_images = np.concatenate([image, mask*255, pred*255], axis=1)\n",
    "    save_image_path = f\"results/test_{index}.png\"\n",
    "    cv2.imwrite(save_image_path, cat_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
